import re
import nltk
from nltk.tokenize import word_tokenize

# Download tokenizer (only first time)
nltk.download('punkt')

print("ðŸ¤– Chatbot: Hello! Type 'bye' to exit.")

# Predefined response patterns
rules = {
    r"hi|hello|hey": "Hello! How can I help you today?",
    r"how are you": "I'm doing great! How about you?",
    r"your name": "I am a rule-based chatbot built using Python.",
    r"help": "Sure! You can ask me about greetings, time, date, or basic info.",
    r"time": "I don't have a watch, but it's always a good time to learn!",
    r"date": "I can't track dates, but today is a great day to code!",
    r"thank you|thanks": "You're welcome! ðŸ˜Š",
    r"bye|exit|quit": "Goodbye! Have a nice day ðŸ‘‹"
}

def tokenize_text(text):
    """
    Tokenizes input sentence into words
    """
    tokens = word_tokenize(text.lower())
    return tokens

def generate_response(user_input):
    """
    Matches user input with regex rules
    """
    for pattern, response in rules.items():
        if re.search(pattern, user_input):
            return response
    return "Sorry, I didn't understand that. Can you rephrase?"

# Chat loop
while True:
    user_input = input("You: ").lower()

    if user_input == "bye":
        print("ðŸ¤– Chatbot:", rules[r"bye|exit|quit"])
        break

    tokens = tokenize_text(user_input)
    response = generate_response(user_input)

    print("ðŸ¤– Chatbot:", response)
